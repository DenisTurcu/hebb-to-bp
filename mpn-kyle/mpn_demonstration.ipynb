{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":7719,"status":"ok","timestamp":1656000771686,"user":{"displayName":"Kyle Aitken","userId":"05799510688644620743"},"user_tz":420},"id":"1eJ_sWhepcCm"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.decomposition import PCA\n","import copy\n","\n","import torch\n","import torch.nn.functional as F\n","\n","import sys\n"," \n","# sys.path.append('/content/drive/MyDrive/neuro_research/stp_networks/')\n","sys.path.append('./paper/')\n","import networks as nets\n","import net_utils as net_utils\n","import int_data as syn\n","import analysis as analysis\n","import context_data as context\n","from data import generate_recog_data, generate_recog_data_batch\n","from plotting import plot_generalization, get_recog_positive_rates\n","\n","c_vals = ['firebrick', 'darkgreen', 'blue', 'darkorange', 'm', 'deeppink', 'r', 'gray', 'g', 'navy', \n","                'y', 'purple', 'cyan', 'olive', 'skyblue', 'pink', 'tan']\n","c_vals_l = ['salmon', 'limegreen', 'cornflowerblue', 'bisque', 'plum', 'pink', 'tomato', 'lightgray', 'g', 'b', \n","                      'y', 'purple', 'cyan', 'olive', 'skyblue', 'pink', 'tan']\n","\n","def participation_ratio_vector(C):\n","    \"\"\"Computes the participation ratio of a vector of variances.\"\"\"\n","    return np.sum(C) ** 2 / np.sum(C*C)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":169,"status":"ok","timestamp":1656005314107,"user":{"displayName":"Kyle Aitken","userId":"05799510688644620743"},"user_tz":420},"id":"tzqhCn251DbR","outputId":"ffb6d1d4-a0d1-4b24-b874-2df1d21a101f"},"outputs":[],"source":["# # Reload modules if changes have been made to them\n","# from importlib import reload\n","\n","# reload(net_utils)\n","# reload(nets)\n","# reload(syn)\n","# reload(analysis)\n","# reload(context)"]},{"cell_type":"markdown","metadata":{"id":"mwgR4aBhaGDj"},"source":["Define some helpful functions for training that will be used below."]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":370,"status":"ok","timestamp":1656009379701,"user":{"displayName":"Kyle Aitken","userId":"05799510688644620743"},"user_tz":420},"id":"BM-bqO2HdTPk"},"outputs":[],"source":["from net_utils import xe_classifier_accuracy\n","\n","def init_net(net_params, verbose=True):\n","    \n","    # initialize net with default values\n","    input_dims = [net_params['n_inputs'], net_params['n_hidden'], net_params['n_outputs']]\n","\n","    if net_params['netType'] in ('MPN',):\n","        # netClass = nets.HebbNet\n","        netClass = MultiPlasticNet\n","    elif net_params['netType'] in ('MPN2',):\n","        netClass = MultiPlasticNetTwo        \n","        input_dims.insert(1, net_params['n_hidden'])\n","    elif net_params['netType'] in ('MPN_rec',):\n","        netClass = MultiPlasticNetRec   \n","    else:\n","        raise ValueError('netType not recognized.')\n","\n","    net = netClass(input_dims, verbose=verbose, MAct=net_params['MAct'])\n","\n","    return net\n","\n","def train_network(net_params, toy_params, current_net=None, save=False, save_root='', \n","                  set_seed=True, verbose=True):\n","    \"\"\" \n","    Code to train a single network. \n","    \n","    OUTPUTS:\n","    net: the trained network\n","    toy_params: these are updated when data is generated\n","\n","    \"\"\"\n","\n","    # Sets the random seed for reproducibility (this affects both data generation and network)\n","    if 'seed' in net_params and set_seed:\n","        if net_params['seed'] is not None: \n","            np.random.seed(seed=net_params['seed'])\n","            torch.manual_seed(net_params['seed'])\n","    \n","    # Intitializes network and puts it on device\n","    if net_params['cuda']:\n","        if verbose: print('Using CUDA...')\n","        device = torch.device('cuda')\n","    else:\n","        if verbose: print('Using CPU...')\n","        device = torch.device('cpu')\n","\n","    net = init_net(net_params, verbose=verbose)\n","    net.to(device)\n","\n","    # Continually generates new data to train on\n","    # This will iterate in loop so that it only sees each type of data a set amount of times\n","    net_params['epochs'] = 0 if current_net is None else net.hist['epoch']\n","    validData, validOutputMask, _ = syn.generate_data(\n","        net_params['valid_set_size'], toy_params, net_params['n_outputs'], \n","        verbose=False, auto_balance=False, device=device)\n","    early_stop = False\n","    new_thresh = True # Triggers threshold setting for first call of .fit, but turns off after first call\n","\n","    while not early_stop:\n","        net_params['epochs'] += 10 # Number of times each example is passed to the network\n","        trainData, trainOutputMask, toy_params = syn.generate_data(\n","            net_params['train_set_size'], toy_params, net_params['n_outputs'], \n","            verbose=False, auto_balance=False, device=device)\n","        \n","        early_stop = net.fit('sequence', epochs=net_params['epochs'], \n","                             trainData=trainData, batchSize=net_params['batch_size'],\n","                             validBatch=validData[:,:,:], learningRate=net_params['learning_rate'],\n","                             newThresh=new_thresh, monitorFreq=50, \n","                             trainOutputMask=trainOutputMask, validOutputMask=validOutputMask,\n","                             validStopThres=net_params['accEarlyStop'], weightReg=net_params['weight_reg'], \n","                             regLambda=net_params['reg_lambda'], gradientClip=net_params['gradient_clip'],\n","                             earlyStopValid=net_params['validEarlyStop'], minMaxIter=net_params['minMaxIter']) \n","        new_thresh = False   \n","\n","    return net, toy_params, net_params"]},{"cell_type":"markdown","metadata":{"id":"zWK07NUu0YQP"},"source":["### Two-layer MPN"]},{"cell_type":"markdown","metadata":{"id":"X-GEu6qOZ7mk"},"source":["This is a stripped-down version of the two-layer MPN network used in the paper, where the first weight layer has two types of plasticity and the readout layer is only trained with backprop. See `networks` for full version."]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":182,"status":"ok","timestamp":1656004622115,"user":{"displayName":"Kyle Aitken","userId":"05799510688644620743"},"user_tz":420},"id":"TGvBslhuhkR_"},"outputs":[],"source":["from torch import nn\n","import torch.nn.functional as F\n","from networks import MultiPlasticLayer\n","from net_utils import StatefulBase, random_weight_init, xe_classifier_accuracy\n","\n","\n","class MultiPlasticNet(StatefulBase):\n","    \"\"\"\n","    Two-layer feedforward setup, with single multi-plastic layer followed by a readout layer.\n","\n","    Same architecture used in \"Neural Population Dynamics of Computing with Synaptic Modulations\"\n","    \"\"\"\n","\n","    def __init__(self, init, verbose=True, **mpnArgs):\n","        super(MultiPlasticNet, self).__init__()\n","\n","        Nx, Nh, Ny = init\n","        # For readouts\n","        W, b = random_weight_init([Nh, Ny], bias=True)\n","\n","        self.n_inputs = Nx\n","        self.n_hidden = Nh\n","        self.n_outputs = Ny\n","\n","        self.loss_fn = F.cross_entropy  # Reductions is mean by default\n","        self.acc_fn = xe_classifier_accuracy\n","\n","        # Creates the input MP layer\n","        self.mp_layer = MultiPlasticLayer(\n","            (self.n_inputs, self.n_hidden), verbose=verbose, **mpnArgs\n","        )\n","\n","        # Input layer activation\n","        self.f = torch.tanh\n","        # Readout layer\n","        self.w2 = nn.Parameter(torch.tensor(W[0], dtype=torch.float))\n","        # Readout bias is not used (easier interpretting readouts in the latter)'\n","        self.register_buffer(\"b2\", torch.zeros_like(torch.tensor(b[0])))\n","\n","    def reset_state(self, batchSize=1):\n","        \"\"\"\n","        Resets states of all internal layer SM matrices\n","        \"\"\"\n","        self.mp_layer.reset_state(batchSize=batchSize)\n","\n","    def forward(self, x, debug=False):\n","        \"\"\"\n","        This modifies the internal state of the model (self.M).\n","        Don't call twice in a row unless you want to update self.M twice!\n","\n","        x.shape: [B, Nx]\n","        b1.shape: [Nh]\n","        w1.shape=[Nx,Nh],\n","        M.shape=[B,Nh,Nx],\n","\n","        \"\"\"\n","        # Apply input multi-plastic layer, returns pre-activation\n","        h_tilde = self.mp_layer(x, debug=debug)\n","        h = self.f(h_tilde)\n","\n","        # M updated internally when this is called\n","        self.mp_layer.update_sm_matrix(x, h)\n","\n","        # (1, Ny) + [(B, Nh,) x (Nh, Ny) = (B, Ny)] = (B, Ny)\n","        y_tilde = self.b2.unsqueeze(0) + torch.mm(h.squeeze(dim=2), torch.transpose(self.w2, 0, 1))\n","        y = y_tilde\n","\n","        if debug:\n","            return h_tilde, h, y_tilde, y, self.mp_layer.M\n","        else:\n","            return y\n","\n","    def evaluate(self, batch):\n","        \"\"\"\n","        Runs a full sequence of the given back size through the network.\n","        \"\"\"\n","        # Begin by resetting the state\n","        self.reset_state(batchSize=batch[0].shape[0])\n","\n","        out_size = torch.Size(\n","            [batch[1].shape[0], batch[1].shape[1], self.n_outputs]\n","        )  # [B, T, Ny]\n","        out = torch.empty(\n","            out_size, dtype=torch.float, layout=batch[1].layout, device=batch[1].device\n","        )\n","\n","        for time_idx in range(batch[0].shape[1]):\n","            x = batch[0][:, time_idx, :]  # [B, Nx]\n","            out[:, time_idx] = self(x)\n","\n","        return out\n","\n","    @torch.no_grad()\n","    def evaluate_debug(self, batch, batchMask=None, acc=True, reset=True):\n","        \"\"\"\n","        Runs a full sequence of the given back size through the network, but now keeps track of all sorts of parameters\n","        \"\"\"\n","        B = batch[0].shape[0]\n","\n","        if reset:\n","            self.reset_state(batchSize=B)\n","\n","        Nx = self.n_inputs\n","        Nh = self.n_hidden\n","        Ny = self.n_outputs\n","        T = batch[1].shape[1]\n","        db = {\n","            \"x\": torch.empty(B, T, Nx),\n","            \"h_tilde\": torch.empty(B, T, Nh),\n","            \"h\": torch.empty(B, T, Nh),\n","            \"Wxb\": torch.empty(B, T, Nh),\n","            \"M\": torch.empty(B, T, Nh, Nx),\n","            \"Mx\": torch.empty(B, T, Nh),\n","            \"y_tilde\": torch.empty(B, T, Ny),\n","            \"out\": torch.empty(B, T, Ny),\n","        }\n","        for time_idx in range(batch[0].shape[1]):\n","            x = batch[0][:, time_idx, :]  # [B, Nx]\n","            db[\"x\"][:, time_idx, :] = x\n","\n","            (\n","                db[\"h_tilde\"][:, time_idx],\n","                db[\"h\"][:, time_idx, :],\n","                db[\"y_tilde\"][:, time_idx, :],\n","                db[\"out\"][:, time_idx, :],\n","                db[\"M\"][:, time_idx, :],\n","            ) = self(x, debug=True)\n","            db[\"Mx\"][:, time_idx, :] = torch.bmm(\n","                self.mp_layer.M, x.unsqueeze(2)\n","            ).squeeze(2)\n","\n","            db[\"Wxb\"][:, time_idx] = self.mp_layer.b1.unsqueeze(0) + torch.mm(\n","                x, torch.transpose(self.mp_layer.w1, 0, 1)\n","            )\n","\n","        if acc:\n","            db[\"acc\"] = self.accuracy(\n","                batch, out=db[\"out\"].to(self.w2.device), outputMask=batchMask\n","            ).item()\n","\n","        return db"]},{"cell_type":"markdown","metadata":{"id":"9R-eXVLehby4"},"source":["#### Train"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37663,"status":"ok","timestamp":1656004809573,"user":{"displayName":"Kyle Aitken","userId":"05799510688644620743"},"user_tz":420},"id":"5I497ckESEE0","outputId":"1a9f947b-c41d-4e7c-d98c-d6f7f3bb21e5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using CPU...\n","MP Layer parameters:\n","  MP Type: Additive // Activation: sigmoid // (Nx, Ny) = (50, 100)\n","  Layer bias: trainable // Sparsification: 0.00 // Layer Noise: None\n","  SM matrix parameters:\n","    M update: Hebbian // M Act: linear // M0: zeros\n","    Eta: scalar // Lam: scalar // Lambda_max: 1.00\n","Train parameters:\n","  Loss: XE // LR: 1.00e-03 // Weight reg: L1, coef: 1.0e-04 // Gradient clip: 1.0e+01\n","Iter:0 lr:1.000e-03 grad:8.695 train_loss:1.2636 train_acc:0.250 valid_loss:1.1917 valid_acc:0.358\n","Iter:50 lr:1.000e-03 grad:6.018 train_loss:1.1525 train_acc:0.219 valid_loss:1.1317 valid_acc:0.334\n","Iter:100 lr:1.000e-03 grad:3.974 train_loss:1.1200 train_acc:0.297 valid_loss:1.1213 valid_acc:0.308\n","  Early Stop: maximum iterations reached, acc: 0.33\n"]}],"source":["########## Toy data parameters ##########\n","toy_params = {\n","    'data_type': 'int', \n","    \n","    'phrase_length': 20,\n","    'n_classes': 3,\n","    'input_type': 'binary',    # one_hot, binary, binary1-1\n","    'input_size': 50,          # defaults to length of words\n","    'include_eos': True,\n","\n","    'n_delay': 0, # Inserts delay words (>0: at end, <0: at beginning)\n","\n","    'uniform_score': True, # Uniform distribution over scores=\n","}\n","\n","net_params = {\n","    'netType': 'MPN', # MPN, MPN2, MPN_rec\n","    'n_inputs': toy_params['input_size'],           # input dim\n","    'n_hidden': 100,                                # hidden dim\n","    'n_outputs': toy_params['n_classes'],           # output dim\n","\n","    'MAct': None, # Activation function of M updates\n","\n","    # Train parameters\n","    'learning_rate': 1e-3,\n","    'weight_reg': 'L1',\n","    'reg_lambda': 1e-4,\n","    'gradient_clip': 10,\n","    \n","    'validEarlyStop': False,      # Early stop when average validation loss saturates\n","    'accEarlyStop': 0.98,         # Accuracy to stop early at (None to ignore)\n","    'minMaxIter': (50, 100),  # Bounds on training time\n","    'seed': 2001,                 # This seed is used to generate training/valid data too\n","\n","    'train_set_size': 3200,\n","    'valid_set_size': 500,\n","    'batch_size': 64,\n","    'epochs': 40,\n","    # 'cuda': True,\n","    'cuda': False,\n","}\n","\n","net_params['train_mode'] = 'seq_inf'\n","\n","net, toy_params, net_params = train_network(net_params, toy_params)"]},{"cell_type":"markdown","metadata":{"id":"PzHB-C6_3S84"},"source":["See training history"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":296},"executionInfo":{"elapsed":442,"status":"ok","timestamp":1656004813519,"user":{"displayName":"Kyle Aitken","userId":"05799510688644620743"},"user_tz":420},"id":"jQlBDYt35UjT","outputId":"195effe4-b856-405e-94cd-440184ee085a"},"outputs":[{"data":{"text/plain":["(0.8960387229919434, 1.5163503170013428)"]},"execution_count":27,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 600x400 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["fig, ax1 = plt.subplots(1, 1, figsize=(6,4))\n","\n","ax1.plot(net.hist['iters_monitor'], net.hist['train_loss'], color=c_vals[0], label='Train')\n","ax1.plot(net.hist['iters_monitor'], net.hist['valid_loss'], color=c_vals[1], label='Test')\n","ax1.plot(net.hist['iters_monitor'], net.hist['avg_valid_loss'], color=c_vals[2], label='Avg Test')\n","\n","ax1.set_xlabel('Step')\n","ax1.set_ylabel('Loss (XE)')\n","ax1.legend()\n","\n","ax1.axhline(0.0, color='k', linestyle='dashed')\n","\n","ax1.set_yscale('log')\n","\n","ax1.set_ylim((0.8*np.min(net.hist['train_loss']),\n","              1.2*np.max(net.hist['train_loss'])))"]},{"cell_type":"markdown","metadata":{"id":"XTHESuP1LKnL"},"source":["#### Visualize dynamics"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":754,"status":"ok","timestamp":1656004817019,"user":{"displayName":"Kyle Aitken","userId":"05799510688644620743"},"user_tz":420},"id":"HYQ21hT2-FXE","outputId":"29243f63-6287-4174-8c31-507655dd1da8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Synthentic data generated in: 0.17 sec. Autobalanced: False. Uniform score: True. Eliminate ties: True\n"]},{"ename":"TypeError","evalue":"tanh(): argument 'input' (position 1) must be Tensor, not tuple","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[28], line 9\u001b[0m\n\u001b[1;32m      4\u001b[0m device \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39mw2\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m      6\u001b[0m testData, testOutputMask, testRaw, _ \u001b[38;5;241m=\u001b[39m syn\u001b[38;5;241m.\u001b[39mgenerate_data(\n\u001b[1;32m      7\u001b[0m     test_set_size, toy_params, net_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_outputs\u001b[39m\u001b[38;5;124m'\u001b[39m], auto_balance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[1;32m      8\u001b[0m     raw_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m----> 9\u001b[0m db \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39mevaluate_debug(testData[:,:,:], batchMask\u001b[38;5;241m=\u001b[39mtestOutputMask)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(db[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m     13\u001b[0m labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(testData[:,:,:][\u001b[38;5;241m1\u001b[39m][:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu())\n","File \u001b[0;32m/opt/anaconda3/envs/h2bp/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","Cell \u001b[0;32mIn[24], line 127\u001b[0m, in \u001b[0;36mMultiPlasticNet.evaluate_debug\u001b[0;34m(self, batch, batchMask, acc, reset)\u001b[0m\n\u001b[1;32m    118\u001b[0m x \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m][:, time_idx, :]  \u001b[38;5;66;03m# [B, Nx]\u001b[39;00m\n\u001b[1;32m    119\u001b[0m db[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m][:, time_idx, :] \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    121\u001b[0m (\n\u001b[1;32m    122\u001b[0m     db[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh_tilde\u001b[39m\u001b[38;5;124m\"\u001b[39m][:, time_idx],\n\u001b[1;32m    123\u001b[0m     db[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m\"\u001b[39m][:, time_idx, :],\n\u001b[1;32m    124\u001b[0m     db[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_tilde\u001b[39m\u001b[38;5;124m\"\u001b[39m][:, time_idx, :],\n\u001b[1;32m    125\u001b[0m     db[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m\"\u001b[39m][:, time_idx, :],\n\u001b[1;32m    126\u001b[0m     db[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m][:, time_idx, :],\n\u001b[0;32m--> 127\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(x, debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    128\u001b[0m db[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMx\u001b[39m\u001b[38;5;124m\"\u001b[39m][:, time_idx, :] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmp_layer\u001b[38;5;241m.\u001b[39mM, x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    130\u001b[0m )\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    132\u001b[0m db[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWxb\u001b[39m\u001b[38;5;124m\"\u001b[39m][:, time_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmp_layer\u001b[38;5;241m.\u001b[39mb1\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mmm(\n\u001b[1;32m    133\u001b[0m     x, torch\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmp_layer\u001b[38;5;241m.\u001b[39mw1, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    134\u001b[0m )\n","File \u001b[0;32m/opt/anaconda3/envs/h2bp/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m/opt/anaconda3/envs/h2bp/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[24], line 59\u001b[0m, in \u001b[0;36mMultiPlasticNet.forward\u001b[0;34m(self, x, debug)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Apply input multi-plastic layer, returns pre-activation\u001b[39;00m\n\u001b[1;32m     58\u001b[0m h_tilde \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmp_layer(x, debug\u001b[38;5;241m=\u001b[39mdebug)\n\u001b[0;32m---> 59\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf(h_tilde)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# M updated internally when this is called\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmp_layer\u001b[38;5;241m.\u001b[39mupdate_sm_matrix(x, h)\n","\u001b[0;31mTypeError\u001b[0m: tanh(): argument 'input' (position 1) must be Tensor, not tuple"]}],"source":["from torch.utils.data import TensorDataset\n","\n","test_set_size = 1000\n","device = net.w2.device\n","\n","testData, testOutputMask, testRaw, _ = syn.generate_data(\n","    test_set_size, toy_params, net_params['n_outputs'], auto_balance=False, \n","    raw_data=True, device=device)\n","db = net.evaluate_debug(testData[:,:,:], batchMask=testOutputMask)\n","\n","print('Accuracy: {:.3f}'.format(db['acc']))\n","\n","labels = np.array(testData[:,:,:][1][:, -1, 0].cpu())\n","hs = db['h'].cpu().numpy()\n","print('Hidden size:', hs.shape)\n","\n","ro_matrix = np.array(net.w2.detach().cpu())\n","print('RO shape', ro_matrix.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":364},"executionInfo":{"elapsed":27028,"status":"ok","timestamp":1656004846489,"user":{"displayName":"Kyle Aitken","userId":"05799510688644620743"},"user_tz":420},"id":"m0lXr6Agv6Fa","outputId":"3dfa8ac1-bac4-4391-8129-a9d7c8506a46"},"outputs":[],"source":["n_components = 100\n","hidden_PCA = PCA(n_components=n_components)\n","\n","hidden_PCA.fit(hs.reshape((-1, hs.shape[-1])))\n","\n","hs_pca = np.zeros((hs.shape[0], hs.shape[1], n_components,))\n","\n","for batch_idx in range(hs.shape[0]):\n","    hs_pca[batch_idx] = hidden_PCA.transform(hs[batch_idx])\n","\n","zero_matrix_pca = hidden_PCA.transform(np.zeros_like(ro_matrix))\n","ro_matrix_pca = hidden_PCA.transform(ro_matrix)\n","\n","print('PCA shape:', hs_pca.shape)\n","print('Variances:', ['{:.2f}'.format(var) for var in hidden_PCA.explained_variance_[:10]])\n","print('PR: {:.2f}'.format(participation_ratio_vector(hidden_PCA.explained_variance_)))\n","\n","fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(16,4))\n","\n","pcxs = (0, 0, 1)\n","pcys = (1, 2, 2)\n","\n","phrase_len = hs.shape[1]\n","\n","n_rand_examples = 2\n","rand_example_idxs = np.random.randint(hs.shape[0], size=(n_rand_examples,))\n","\n","for ax, pcx, pcy in zip((ax1, ax2, ax3), pcxs, pcys):\n","    for example_idx in range(hs.shape[0]): # Hidden activity\n","        ax.scatter(hs_pca[example_idx, :, pcx], hs_pca[example_idx, :, pcy], linewidth=0.0,\n","                   marker='.', color=c_vals_l[labels[example_idx]], zorder=0, alpha=0.5)\n","        ax.scatter(hs_pca[example_idx, -1, pcx], hs_pca[example_idx, -1, pcy], marker='o',\n","                   color=c_vals[labels[example_idx]], zorder=5, alpha=0.5)\n","\n","    for ro_idx in range(net_params['n_outputs']): # Readouts\n","        ax.plot([zero_matrix_pca[ro_idx, pcx], ro_matrix_pca[ro_idx, pcx]], \n","                [zero_matrix_pca[ro_idx, pcy], ro_matrix_pca[ro_idx, pcy]],\n","                 color=c_vals[ro_idx], linewidth=3.0, zorder=10)\n","\n","    for rand_example_idx in rand_example_idxs: # Example trajectories\n","        ax.plot(hs_pca[rand_example_idx, :, pcx], hs_pca[rand_example_idx, :, pcy],\n","                color=c_vals[labels[rand_example_idx]], zorder=1)\n","\n","    ax.set_xlabel('PC{}'.format(pcx))\n","    ax.set_ylabel('PC{}'.format(pcy))\n","    \n","ax2.set_title('Hidden state PC plots (color by phrase label)')"]},{"cell_type":"markdown","metadata":{"id":"WHXciIjTy3tw"},"source":["### Three-layer MPN"]},{"cell_type":"markdown","metadata":{"id":"FecvS1UFZtBF"},"source":["Same as the two-layer MPN, but now has an additional feedforward layer that also has multi-plasticity (so the first two weight layers have multi-plasticity, but the readout layer is still only trained with backprop). Stripped down version, see `networks` for full version."]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":164,"status":"ok","timestamp":1656005495512,"user":{"displayName":"Kyle Aitken","userId":"05799510688644620743"},"user_tz":420},"id":"AiaGpnjolQqp"},"outputs":[],"source":["from torch import nn\n","import torch.nn.functional as F\n","from networks import MultiPlasticLayer\n","from net_utils import StatefulBase, random_weight_init, xe_classifier_accuracy\n","\n","class MultiPlasticNetTwo(StatefulBase):\n","    \"\"\"\n","    Same as above but has two multi-plastic layers followed by a readout layer.\n","    \"\"\"     \n","    def __init__(self, init, verbose=True, **mpnArgs):        \n","        super(MultiPlasticNetTwo, self).__init__()        \n","        \n","        Nx,Nh1,Nh2,Ny = init\n","        # For readouts\n","        W,b = random_weight_init([Nh2,Ny], bias=True)\n","        \n","        self.n_inputs = Nx\n","        self.n_hidden1 = Nh1\n","        self.n_hidden2 = Nh2\n","        self.n_outputs = Ny \n","        \n","        self.loss_fn = F.cross_entropy # Reductions is mean by default\n","        self.acc_fn = xe_classifier_accuracy \n","\n","        # Creates the MP layers\n","        self.mp_layer1 = MultiPlasticLayer((self.n_inputs, self.n_hidden1), verbose=verbose, **mpnArgs)\n","        self.mp_layer2 = MultiPlasticLayer((self.n_hidden1, self.n_hidden2), verbose=verbose, **mpnArgs)\n","\n","        # Hidden layer activations\n","        self.f1 = torch.tanh\n","        self.f2 = torch.tanh\n","\n","        # Readout layer\n","        self.w2 = nn.Parameter(torch.tensor(W[0], dtype=torch.float))\n","        # Readout bias is not used (easier interpretting readouts in the latter)\n","        self.register_buffer('b2', torch.zeros_like(torch.tensor(b[0])))\n","    \n","    def reset_state(self, batchSize=1):\n","        \"\"\"\n","        Resets states of all internal layer SM matrices\n","        \"\"\"\n","        self.mp_layer1.reset_state(batchSize=batchSize)\n","        self.mp_layer2.reset_state(batchSize=batchSize)    \n","\n","    def forward(self, x, debug=False):\n","        \"\"\"\n","        This modifies the internal state of the model (self.M). \n","        Don't call twice in a row unless you want to update self.M twice!\n","\n","        x.shape: [B, Nx]\n","        b1.shape: [Nh]\n","        w1.shape=[Nx,Nh], \n","        A.shape=[B,Nh,Nx], \n","\n","        \"\"\"\n","\n","        # Apply input multi-plastic layer, returns pre-activation\n","        h_tilde1 = self.mp_layer1(x, debug=debug)\n","        h1 = self.f1(h_tilde1)\n","\n","        # M updated internally \n","        self.mp_layer1.update_sm_matrix(x, h1)        \n","        \n","        h_tilde2 = self.mp_layer2(h1, debug=debug)\n","        h2 = self.f2(h_tilde2) \n","\n","        self.mp_layer2.update_sm_matrix(h1, h2)  \n","\n","        # (1, Ny) + [(B, Nh,) x (Nh, Ny) = (B, Ny)] = (B, Ny)\n","        y_tilde = self.b2.unsqueeze(0) + torch.mm(h2, torch.transpose(self.w2, 0, 1)) #output layer activation\n","        y = y_tilde  \n","                           \n","        if debug:\n","            return (h_tilde1, h1, h_tilde2, h2, y_tilde, y, self.mp_layer1.M, self.mp_layer2.M)\n","        else:\n","            return y   \n","     \n","    def evaluate(self, batch):\n","        \"\"\"\n","        Runs a full sequence of the given back size through the network.\n","        \"\"\"\n","        self.reset_state(batchSize=batch[0].shape[0])\n","\n","        out_size = torch.Size([batch[1].shape[0], batch[1].shape[1], self.n_outputs]) # [B, T, Ny]\n","        out = torch.empty(out_size, dtype=torch.float, layout=batch[1].layout, device=batch[1].device)\n","\n","        for time_idx in range(batch[0].shape[1]):\n","\n","            x = batch[0][:, time_idx, :] # [B, Nx]\n","            out[:, time_idx] = self(x)\n","\n","        return out\n","        \n","    @torch.no_grad()    \n","    def evaluate_debug(self, batch, batchMask=None, acc=True, reset=True):\n","        \"\"\" \n","        Runs a full sequence of the given back size through the network, but now keeps track of all sorts of parameters\n","        \"\"\"\n","        B = batch[0].shape[0]\n","\n","        if reset:\n","            self.reset_state(batchSize=B)\n","\n","        Nx = self.n_inputs\n","        Nh1 = self.n_hidden1\n","        Nh2 = self.n_hidden2\n","        Ny = self.n_outputs\n","        T = batch[1].shape[1]\n","        db = {'x' : torch.empty(B,T,Nx),\n","              'h_tilde1' : torch.empty(B,T,Nh1),\n","              'h1' : torch.empty(B,T,Nh1),\n","              'M1': torch.empty(B,T,Nh1,Nx),\n","              'h_tilde2' : torch.empty(B,T,Nh2),\n","              'h2' : torch.empty(B,T,Nh2),\n","              'M2': torch.empty(B,T,Nh2,Nh1),\n","              'y_tilde' : torch.empty(B,T,Ny),\n","              'out' : torch.empty(B,T,Ny),\n","              }\n","        for time_idx in range(batch[0].shape[1]):\n","            x = batch[0][:, time_idx, :] # [B, Nx]\n","            db['x'][:,time_idx,:] = x\n","\n","            (db['h_tilde1'][:,time_idx], db['h1'][:,time_idx,:], \n","                db['h_tilde2'][:,time_idx], db['h2'][:,time_idx,:],\n","                db['y_tilde'][:,time_idx,:], db['out'][:,time_idx,:], \n","                db['M1'][:,time_idx,:], db['M2'][:,time_idx,:]) = self(x, debug=True)      \n","            \n","        \n","        if acc:\n","            db['acc'] = self.accuracy(batch, out=db['out'].to(self.w2.device), outputMask=batchMask).item()  \n","                             \n","        return db"]},{"cell_type":"markdown","metadata":{"id":"4c1emzE_lNQx"},"source":["#### Train"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30220,"status":"ok","timestamp":1656005528535,"user":{"displayName":"Kyle Aitken","userId":"05799510688644620743"},"user_tz":420},"id":"fS-FfPsdy3tx","outputId":"aa694f18-5026-43c8-a0be-1336f9f9a586"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using CUDA...\n","MP Layer parameters:\n","  MP Type: Additive // Activation: sigmoid // (Nx, Ny) = (50, 100)\n","  Layer bias: trainable // Sparsification: 0.00 // Layer Noise: None\n","  SM matrix parameters:\n","    M update: Hebbian // M Act: linear // M0: zeros\n","    Eta: scalar // Lam: scalar // Lambda_max: 1.00\n","MP Layer parameters:\n","  MP Type: Additive // Activation: sigmoid // (Nx, Ny) = (100, 100)\n","  Layer bias: trainable // Sparsification: 0.00 // Layer Noise: None\n","  SM matrix parameters:\n","    M update: Hebbian // M Act: linear // M0: zeros\n","    Eta: scalar // Lam: scalar // Lambda_max: 1.00\n"]},{"ename":"AssertionError","evalue":"Torch not compiled with CUDA enabled","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[30], line 44\u001b[0m\n\u001b[1;32m     16\u001b[0m net_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnetType\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMPN2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;66;03m# MPN, MPN2, MPN_rec\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_inputs\u001b[39m\u001b[38;5;124m'\u001b[39m: toy_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_size\u001b[39m\u001b[38;5;124m'\u001b[39m],           \u001b[38;5;66;03m# input dim\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     40\u001b[0m }\n\u001b[1;32m     42\u001b[0m net_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_mode\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseq_inf\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 44\u001b[0m net, toy_params, net_params \u001b[38;5;241m=\u001b[39m train_network(net_params, toy_params)\n","Cell \u001b[0;32mIn[4], line 49\u001b[0m, in \u001b[0;36mtrain_network\u001b[0;34m(net_params, toy_params, current_net, save, save_root, set_seed, verbose)\u001b[0m\n\u001b[1;32m     46\u001b[0m     device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     48\u001b[0m net \u001b[38;5;241m=\u001b[39m init_net(net_params, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[0;32m---> 49\u001b[0m net\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Continually generates new data to train on\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# This will iterate in loop so that it only sees each type of data a set amount of times\u001b[39;00m\n\u001b[1;32m     53\u001b[0m net_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m current_net \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m net\u001b[38;5;241m.\u001b[39mhist[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m]\n","File \u001b[0;32m/opt/anaconda3/envs/h2bp/lib/python3.12/site-packages/torch/nn/modules/module.py:1174\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1172\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(convert)\n","File \u001b[0;32m/opt/anaconda3/envs/h2bp/lib/python3.12/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[0;32m/opt/anaconda3/envs/h2bp/lib/python3.12/site-packages/torch/nn/modules/module.py:805\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 805\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m fn(param)\n\u001b[1;32m    806\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n","File \u001b[0;32m/opt/anaconda3/envs/h2bp/lib/python3.12/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1155\u001b[0m             device,\n\u001b[1;32m   1156\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m             non_blocking,\n\u001b[1;32m   1158\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1159\u001b[0m         )\n\u001b[0;32m-> 1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1161\u001b[0m         device,\n\u001b[1;32m   1162\u001b[0m         dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1163\u001b[0m         non_blocking,\n\u001b[1;32m   1164\u001b[0m     )\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n","File \u001b[0;32m/opt/anaconda3/envs/h2bp/lib/python3.12/site-packages/torch/cuda/__init__.py:305\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    303\u001b[0m     )\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    309\u001b[0m     )\n","\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"]}],"source":["########## Toy data parameters ##########\n","toy_params = {\n","    'data_type': 'int', \n","    \n","    'phrase_length': 20,\n","    'n_classes': 3,\n","    'input_type': 'binary',    # one_hot, binary, binary1-1\n","    'input_size': 50,          # defaults to length of words\n","    'include_eos': True,\n","\n","    'n_delay': 0, # Inserts delay words (>0: at end, <0: at beginning)\n","\n","    'uniform_score': True, # Uniform distribution over scores=\n","}\n","\n","net_params = {\n","    'netType': 'MPN2', # MPN, MPN2, MPN_rec\n","    'n_inputs': toy_params['input_size'],           # input dim\n","    'n_hidden': 100,                                # hidden dim\n","    'n_outputs': toy_params['n_classes'],         # output dim\n","\n","    'MAct': None, # Activation function of M updates\n","\n","    # Train parameters\n","    'learning_rate': 1e-3,\n","    'weight_reg': 'L1',\n","    'reg_lambda': 1e-4,\n","    'gradient_clip': 10,\n","    \n","    'validEarlyStop': False,     # Early stop when average validation loss saturates\n","    'accEarlyStop': 0.98,       # Accuracy to stop early at (None to ignore)\n","    'minMaxIter': (1000, 10000),  # Bounds on training time\n","    'seed': 2001,               # This seed is used to generate training/valid data too\n","\n","    'train_set_size': 3200,\n","    'valid_set_size': 500,\n","    'batch_size': 64,\n","    'epochs': 40,\n","    'cuda': True,\n","}\n","\n","net_params['train_mode'] = 'seq_inf'\n","\n","net, toy_params, net_params = train_network(net_params, toy_params)"]},{"cell_type":"markdown","metadata":{"id":"C9AivexVy3tx"},"source":["See training history"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":296},"executionInfo":{"elapsed":507,"status":"ok","timestamp":1656005580230,"user":{"displayName":"Kyle Aitken","userId":"05799510688644620743"},"user_tz":420},"id":"2jLMECxxy3ty","outputId":"a6831051-eb08-4b17-f7ce-4922bc79fa6e"},"outputs":[],"source":["fig, ax1 = plt.subplots(1, 1, figsize=(6,4))\n","\n","ax1.plot(net.hist['iters_monitor'], net.hist['train_loss'], color=c_vals[0], label='Train')\n","ax1.plot(net.hist['iters_monitor'], net.hist['valid_loss'], color=c_vals[1], label='Test')\n","ax1.plot(net.hist['iters_monitor'], net.hist['avg_valid_loss'], color=c_vals[2], label='Avg Test')\n","\n","ax1.set_xlabel('Step')\n","ax1.set_ylabel('Loss (XE)')\n","ax1.legend()\n","\n","ax1.axhline(0.0, color='k', linestyle='dashed')\n","\n","ax1.set_yscale('log')\n","\n","ax1.set_ylim((0.8*np.min(net.hist['train_loss']),\n","              1.2*np.max(net.hist['train_loss'])))"]},{"cell_type":"markdown","metadata":{"id":"ojkZ1Hc4y3ty"},"source":["#### Visualize dynamics"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1316,"status":"ok","timestamp":1656005583725,"user":{"displayName":"Kyle Aitken","userId":"05799510688644620743"},"user_tz":420},"id":"4I9L-gt8y3ty","outputId":"15b70ae6-4a15-4d3d-893e-65a67af04d73"},"outputs":[],"source":["from torch.utils.data import TensorDataset\n","\n","test_set_size = 1000\n","device = net.w2.device\n","\n","testData, testOutputMask, testRaw, _ = syn.generate_data(\n","    test_set_size, toy_params, net_params['n_outputs'], auto_balance=False, \n","    raw_data=True, device=device)\n","db = net.evaluate_debug(testData[:,:,:], batchMask=testOutputMask)\n","\n","print('Accuracy: {:.3f}'.format(db['acc']))\n","\n","labels = np.array(testData[:,:,:][1][:, -1, 0].cpu())\n","h1s = db['h1'].cpu().numpy()\n","h2s = db['h2'].cpu().numpy()\n","print('Hidden1 size:', h1s.shape)\n","print('Hidden2 size:', h2s.shape)\n","\n","ro_matrix = np.array(net.w2.detach().cpu())\n","print('RO shape', ro_matrix.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":648},"executionInfo":{"elapsed":61187,"status":"ok","timestamp":1656005646884,"user":{"displayName":"Kyle Aitken","userId":"05799510688644620743"},"user_tz":420},"id":"JgO2BMCAy3ty","outputId":"9fad7ca6-4f5e-4c6e-b481-327dafde1393"},"outputs":[],"source":["n_components = 100\n","\n","n_rand_examples = 2\n","rand_example_idxs = np.random.randint(hs.shape[0], size=(n_rand_examples,))\n","\n","for hs_idx, hs in enumerate((h1s, h2s)):\n","\n","    hidden_PCA = PCA(n_components=n_components)\n","\n","    hidden_PCA.fit(hs.reshape((-1, hs.shape[-1])))\n","\n","    hs_pca = np.zeros((hs.shape[0], hs.shape[1], n_components,))\n","\n","    for batch_idx in range(hs.shape[0]):\n","        hs_pca[batch_idx] = hidden_PCA.transform(hs[batch_idx])\n","\n","    zero_matrix_pca = hidden_PCA.transform(np.zeros_like(ro_matrix))\n","    ro_matrix_pca = hidden_PCA.transform(ro_matrix)\n","\n","    print('PCA shape:', hs_pca.shape)\n","    print('Variances:', ['{:.2f}'.format(var) for var in hidden_PCA.explained_variance_[:10]])\n","    print('PR: {:.2f}'.format(participation_ratio_vector(hidden_PCA.explained_variance_)))\n","\n","    if hs_idx == 0:\n","        fig1, axs = plt.subplots(1, 3, figsize=(16,4))\n","    else:\n","        fig2, axs = plt.subplots(1, 3, figsize=(16,4))\n","\n","    pcxs = (0, 0, 1)\n","    pcys = (1, 2, 2)\n","\n","    phrase_len = hs.shape[1]\n","\n","    for ax, pcx, pcy in zip(axs, pcxs, pcys):\n","        for batch_idx in range(hs.shape[0]): # Hidden activity\n","            ax.scatter(hs_pca[batch_idx, :, pcx], hs_pca[batch_idx, :, pcy], linewidth=0.0,\n","                    marker='.', color=c_vals_l[labels[batch_idx]], zorder=0, alpha=0.5)\n","            ax.scatter(hs_pca[batch_idx, -1, pcx], hs_pca[batch_idx, -1, pcy], marker='o',\n","                    color=c_vals[labels[batch_idx]], zorder=5, alpha=0.5)\n","\n","        if hs_idx == 1:\n","            for ro_idx in range(net_params['n_outputs']): # Readouts\n","                ax.plot([zero_matrix_pca[ro_idx, pcx], ro_matrix_pca[ro_idx, pcx]], \n","                        [zero_matrix_pca[ro_idx, pcy], ro_matrix_pca[ro_idx, pcy]],\n","                        color=c_vals[ro_idx], linewidth=3.0, zorder=10)\n","            \n","        for rand_example_idx in rand_example_idxs: # Example trajectories\n","            ax.plot(hs_pca[rand_example_idx, :, pcx], hs_pca[rand_example_idx, :, pcy],\n","                    color=c_vals[labels[rand_example_idx]], zorder=1)\n","\n","        ax.set_xlabel('PC{}'.format(pcx))\n","        ax.set_ylabel('PC{}'.format(pcy))\n","        \n","    ax2.set_title('Hidden {} state PC plots (color by phrase label)'.format(hs_idx+1))"]},{"cell_type":"markdown","metadata":{"id":"wd7z7i2y4lL-"},"source":["### Recurrent MPN"]},{"cell_type":"markdown","metadata":{"id":"p-YiLd0IYgyK"},"source":["Same as the two-layer MPN, but now has a recurrent layer (in the same way a Vanilla RNN has one) that also has multi-plasticity. Note that in order for this to train well, the SM matrix must be bounded, so here we have added a tanh activation function around the M updates. Stripped down version, see `networks` for full version."]},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":188,"status":"ok","timestamp":1656009426979,"user":{"displayName":"Kyle Aitken","userId":"05799510688644620743"},"user_tz":420},"id":"YjjK_kG3n1pT"},"outputs":[],"source":["from torch import nn\n","import torch.nn.functional as F\n","from networks import MultiPlasticLayer\n","from net_utils import StatefulBase, random_weight_init, xe_classifier_accuracy\n","\n","class MultiPlasticNetRec(StatefulBase):\n","    \"\"\"\n","    Recurrent neural network with multi-plastic layers on W_inp and W_rec\n","    \"\"\"     \n","    def __init__(self, init, verbose=True, **mpnArgs):        \n","        super(MultiPlasticNetRec, self).__init__()        \n","\n","        Nx,Nh,Ny = init\n","        # For readouts\n","        W,b = random_weight_init([Nh,Ny], bias=True)\n","        \n","        self.n_inputs = Nx\n","        self.n_hidden = Nh\n","        self.n_outputs = Ny \n","\n","        self.loss_fn = F.cross_entropy # Reductions is mean by default\n","        self.acc_fn = xe_classifier_accuracy \n","\n","        # Creates the input MP layer\n","        self.mp_layer_inp = MultiPlasticLayer((self.n_inputs, self.n_hidden), verbose=verbose, **mpnArgs)\n","        self.mp_layer_rec = MultiPlasticLayer((self.n_hidden, self.n_hidden), verbose=verbose, **mpnArgs)\n","\n","        self.f = torch.tanh\n","        \n","        # Readout layer (always trainable)\n","        self.w2 = nn.Parameter(torch.tensor(W[0], dtype=torch.float))\n","        # Readout bias is not used (easier interpretting readouts in the latter)\n","        self.register_buffer('b2', torch.zeros_like(torch.tensor(b[0])))\n","\n","        # Fixed initial hidden activity\n","        _, b_hidden = random_weight_init([1,Nh], bias=True) \n","        self.register_buffer('h0', torch.zeros_like(torch.tensor(b_hidden[0], dtype=torch.float)))\n","    \n","    def reset_state(self, batchSize=1):\n","        \"\"\"\n","        Resets states of all internal layer SM matrices and hidden layer\n","        \"\"\"\n","        self.mp_layer_inp.reset_state(batchSize=batchSize)\n","        self.mp_layer_rec.reset_state(batchSize=batchSize)    \n","\n","        self.h = torch.ones((batchSize, self.n_hidden), \n","                            device=self.w2.device) #shape=[B,Nh]  \n","        self.h = self.h * self.h0.unsqueeze(0)\n","\n","    def forward(self, x, debug=False, stateOnly=False):\n","        \"\"\"\n","        This modifies the internal state of the model (self.M). \n","        Don't call twice in a row unless you want to update self.M twice!\n","\n","        x.shape: [B, Nx]\n","        b1.shape: [Nh]\n","        w1.shape=[Nx,Nh], \n","        A.shape=[B,Nh,Nx], \n","\n","        \"\"\"\n","\n","        # Apply input multi-plastic layer, returns pre-activation\n","        h_tilde_inp = self.mp_layer_inp(x, debug=debug)\n","        # Recurrent multi-plastic layer\n","        h_tilde_rec = self.mp_layer_rec(self.h, debug=debug)\n","\n","        h_tilde = h_tilde_inp + h_tilde_rec\n","        h = self.f(h_tilde) \n","        \n","        # Ms updated internally\n","        self.mp_layer_inp.update_sm_matrix(x, h)  \n","        self.mp_layer_rec.update_sm_matrix(self.h, h)        \n","\n","        self.h = h\n","\n","        # (1, Ny) + [(B, Nh,) x (Nh, Ny) = (B, Ny)] = (B, Ny)\n","        y_tilde = self.b2.unsqueeze(0) + torch.mm(h, torch.transpose(self.w2, 0, 1)) #output layer activation\n","        y = y_tilde  \n","                           \n","        if debug:\n","            return (h_tilde_inp, h_tilde_rec, h, y_tilde, y, self.mp_layer_inp.M, self.mp_layer_rec.M)\n","        else:\n","            return y   \n","     \n","    def evaluate(self, batch):\n","        \"\"\"\n","        Runs a full sequence of the given back size through the network.\n","        \"\"\"\n","        self.reset_state(batchSize=batch[0].shape[0])\n","        # Output size can differ from batch[1] size because XE loss is now used \n","        out_size = torch.Size([batch[1].shape[0], batch[1].shape[1], self.n_outputs]) # [B, T, Ny]\n","\n","        out = torch.empty(out_size, dtype=torch.float, layout=batch[1].layout, device=batch[1].device)\n","\n","        for time_idx in range(batch[0].shape[1]):\n","\n","            x = batch[0][:, time_idx, :] # [B, Nx]\n","            out[:, time_idx] = self(x)\n","\n","        return out\n","        \n","    @torch.no_grad()    \n","    def evaluate_debug(self, batch, batchMask=None, acc=True, reset=True):\n","        \"\"\" \n","        Runs a full sequence of the given back size through the network, but now keeps track of all sorts of parameters\n","        \"\"\"\n","        B = batch[0].shape[0]\n","\n","        if reset:\n","            self.reset_state(batchSize=B)\n","\n","        Nx = self.n_inputs\n","        Nh = self.n_hidden\n","        Ny = self.n_outputs\n","        T = batch[1].shape[1]\n","        db = {'x' : torch.empty(B,T,Nx),\n","              'h_tilde_inp' : torch.empty(B,T,Nh),\n","              'h_tilde_rec' : torch.empty(B,T,Nh),\n","              'h' : torch.empty(B,T,Nh),\n","              'M_inp': torch.empty(B,T,Nh,Nx),\n","              'M_rec': torch.empty(B,T,Nh,Nh),\n","              'y_tilde' : torch.empty(B,T,Ny),\n","              'out' : torch.empty(B,T,Ny),\n","              }\n","        for time_idx in range(batch[0].shape[1]):\n","            x = batch[0][:, time_idx, :] # [B, Nx]\n","            db['x'][:,time_idx,:] = x\n","\n","            (db['h_tilde_inp'][:,time_idx], db['h_tilde_rec'][:,time_idx,:], \n","                db['h'][:,time_idx],  db['y_tilde'][:,time_idx,:], db['out'][:,time_idx,:], \n","                db['M_inp'][:,time_idx,:], db['M_rec'][:,time_idx,:]) = self(x, debug=True)      \n","        \n","        if acc:\n","            db['acc'] = self.accuracy(batch, out=db['out'].to(self.w2.device), outputMask=batchMask).item()  \n","                             \n","        return db"]},{"cell_type":"markdown","metadata":{"id":"GUwiI01yn0Sc"},"source":["#### Train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36919,"status":"ok","timestamp":1656009467639,"user":{"displayName":"Kyle Aitken","userId":"05799510688644620743"},"user_tz":420},"id":"-eFjQ4Vy4lL_","outputId":"e3822d77-2757-4bed-9d91-cb5da50eb14e"},"outputs":[],"source":["########## Toy data parameters ##########\n","toy_params = {\n","    'data_type': 'int', \n","    \n","    'phrase_length': 20,\n","    'n_classes': 3,\n","    'input_type': 'binary',    # one_hot, binary, binary1-1\n","    'input_size': 50,          # defaults to length of words\n","    'include_eos': True,\n","\n","    'n_delay': 0, # Inserts delay words (>0: at end, <0: at beginning)\n","\n","    'uniform_score': True, # Uniform distribution over scores=\n","}\n","\n","net_params = {\n","    'netType': 'MPN_rec', # MPN, MPN2, MPN_rec\n","    'n_inputs': toy_params['input_size'],           # input dim\n","    'n_hidden': 100,                                # hidden dim\n","    'n_outputs': toy_params['n_classes'],         # output dim\n","\n","    # Train parameters\n","    'learning_rate': 1e-3,\n","    'weight_reg': 'L1',\n","    'reg_lambda': 1e-4,\n","    'gradient_clip': 10,\n","\n","    'MAct': 'tanh',\n","    \n","    'validEarlyStop': False,     # Early stop when average validation loss saturates\n","    'accEarlyStop': 0.98,       # Accuracy to stop early at (None to ignore)\n","    'minMaxIter': (1000, 10000),  # Bounds on training time\n","    'seed': 2001,               # This seed is used to generate training/valid data too\n","\n","    'train_set_size': 3200,\n","    'valid_set_size': 500,\n","    'batch_size': 64,\n","    'epochs': 40,\n","    'cuda': True,\n","}\n","\n","net_params['train_mode'] = 'seq_inf'\n","\n","net, toy_params, net_params = train_network(net_params, toy_params)"]},{"cell_type":"markdown","metadata":{"id":"sjAVgymi4lMA"},"source":["See training history"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":296},"executionInfo":{"elapsed":471,"status":"ok","timestamp":1656009483700,"user":{"displayName":"Kyle Aitken","userId":"05799510688644620743"},"user_tz":420},"id":"4vaqHU324lMA","outputId":"17878f8c-546a-462a-83c6-af31591077bc"},"outputs":[],"source":["fig, ax1 = plt.subplots(1, 1, figsize=(6,4))\n","\n","ax1.plot(net.hist['iters_monitor'], net.hist['train_loss'], color=c_vals[0], label='Train')\n","ax1.plot(net.hist['iters_monitor'], net.hist['valid_loss'], color=c_vals[1], label='Test')\n","ax1.plot(net.hist['iters_monitor'], net.hist['avg_valid_loss'], color=c_vals[2], label='Avg Test')\n","\n","ax1.set_xlabel('Step')\n","ax1.set_ylabel('Loss (XE)')\n","ax1.legend()\n","\n","ax1.axhline(0.0, color='k', linestyle='dashed')\n","\n","ax1.set_yscale('log')\n","\n","ax1.set_ylim((0.8*np.min(net.hist['train_loss']),\n","              1.2*np.max(net.hist['train_loss'])))"]},{"cell_type":"markdown","metadata":{"id":"QNfSnWo54lMA"},"source":["#### Visualize dynamics"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1443,"status":"ok","timestamp":1656009487175,"user":{"displayName":"Kyle Aitken","userId":"05799510688644620743"},"user_tz":420},"id":"7-I9E7Jt4lMA","outputId":"9656f33e-e869-4747-af59-47165d1dd320"},"outputs":[],"source":["from torch.utils.data import TensorDataset\n","\n","test_set_size = 1000\n","device = net.w2.device\n","\n","testData, testOutputMask, testRaw, _ = syn.generate_data(\n","    test_set_size, toy_params, net_params['n_outputs'], auto_balance=False, \n","    raw_data=True, device=device)\n","db = net.evaluate_debug(testData[:,:,:], batchMask=testOutputMask)\n","\n","print('Accuracy: {:.3f}'.format(db['acc']))\n","\n","labels = np.array(testData[:,:,:][1][:, -1, 0].cpu())\n","hs = db['h'].cpu().numpy()\n","print('Hidden size:', hs.shape)\n","\n","ro_matrix = np.array(net.w2.detach().cpu())\n","print('RO shape', ro_matrix.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":364},"executionInfo":{"elapsed":28993,"status":"ok","timestamp":1656009518855,"user":{"displayName":"Kyle Aitken","userId":"05799510688644620743"},"user_tz":420},"id":"2ejOspYu4lMA","outputId":"3a50161e-1892-4dec-a84b-61146d67c587"},"outputs":[],"source":["n_components = 100\n","hidden_PCA = PCA(n_components=n_components)\n","\n","hidden_PCA.fit(hs.reshape((-1, hs.shape[-1])))\n","\n","hs_pca = np.zeros((hs.shape[0], hs.shape[1], n_components,))\n","\n","for batch_idx in range(hs.shape[0]):\n","    hs_pca[batch_idx] = hidden_PCA.transform(hs[batch_idx])\n","\n","zero_matrix_pca = hidden_PCA.transform(np.zeros_like(ro_matrix))\n","ro_matrix_pca = hidden_PCA.transform(ro_matrix)\n","\n","print('PCA shape:', hs_pca.shape)\n","print('Variances:', ['{:.2f}'.format(var) for var in hidden_PCA.explained_variance_[:10]])\n","print('PR: {:.2f}'.format(participation_ratio_vector(hidden_PCA.explained_variance_)))\n","\n","fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(16,4))\n","\n","pcxs = (0, 0, 1)\n","pcys = (1, 2, 2)\n","\n","phrase_len = hs.shape[1]\n","\n","n_rand_examples = 2\n","rand_example_idxs = np.random.randint(hs.shape[0], size=(n_rand_examples,))\n","\n","for ax, pcx, pcy in zip((ax1, ax2, ax3), pcxs, pcys):\n","    for batch_idx in range(hs.shape[0]): # Hidden activity\n","        ax.scatter(hs_pca[batch_idx, :, pcx], hs_pca[batch_idx, :, pcy], linewidth=0.0,\n","                   marker='.', color=c_vals_l[labels[batch_idx]], zorder=0, alpha=0.5)\n","        ax.scatter(hs_pca[batch_idx, -1, pcx], hs_pca[batch_idx, -1, pcy], marker='o',\n","                   color=c_vals[labels[batch_idx]], zorder=5, alpha=0.5)\n","\n","    for ro_idx in range(net_params['n_outputs']): # Readouts\n","        ax.plot([zero_matrix_pca[ro_idx, pcx], ro_matrix_pca[ro_idx, pcx]], \n","                [zero_matrix_pca[ro_idx, pcy], ro_matrix_pca[ro_idx, pcy]],\n","                 color=c_vals[ro_idx], linewidth=3.0, zorder=10)\n","        \n","    for rand_example_idx in rand_example_idxs: # Example trajectories\n","        ax.plot(hs_pca[rand_example_idx, :, pcx], hs_pca[rand_example_idx, :, pcy],\n","                color=c_vals[labels[rand_example_idx]], zorder=1)\n","\n","    ax.set_xlabel('PC{}'.format(pcx))\n","    ax.set_ylabel('PC{}'.format(pcy))\n","    \n","ax2.set_title('Hidden state PC plots (color by phrase label)')"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPYLdX8We4/cW4bBJ4gOZfy","collapsed_sections":[],"mount_file_id":"1L80SVXarJ38Nuo1rQw91367xw9CZwFvR","name":"mpn_demonstration.ipynb","provenance":[{"file_id":"1etuHaI5MZtjtNav_ZFzyAx_cpWHpvmKT","timestamp":1655848907786}],"toc_visible":true},"kernelspec":{"display_name":"h2bp","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"}},"nbformat":4,"nbformat_minor":0}
